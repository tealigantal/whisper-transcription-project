# ===============================================================
#  Whisper âœ training_data.json  +  markup.json
#  åŠŸèƒ½ï¼š
#    â€¢ è¯­éŸ³è½¬æ–‡å­— (Whisper)
#    â€¢ å¡«å……è¯ <filler> æ ‡æ³¨
#    â€¢ åœé¡¿/é™éŸ³ â¸ æ ‡æ³¨ï¼ˆä»…å†™å…¥ markupï¼‰
#    â€¢ ç”Ÿæˆè®­ç»ƒç”¨çº¯æ–‡æœ¬ï¼ˆå«åœé¡¿ *æ¬¡æ•°* & *æ€»æ—¶é•¿*ï¼Œä¸å«é€ç‚¹æ—¶é—´ï¼‰
# ---------------------------------------------------------------
#  ä¾èµ–ï¼š
#     pip install -U openai-whisper  # Whisper å®˜æ–¹åŒ…ï¼ˆå« torchï¼‰
#     pip install -U tiktoken        # (å¯é€‰) token ç»Ÿè®¡æ›´å‡†
#     pip install -U wordfreq        # (å¯é€‰) ç”Ÿåƒ»è¯è¾¨è¯†
#  Windows éœ€è‡ªè£… ffmpeg å¹¶åŠ å…¥ PATH
# ===============================================================

import os, subprocess, whisper, json, re, tempfile, sys, warnings, html
from contextlib import redirect_stdout, redirect_stderr
from datetime import datetime

warnings.filterwarnings("ignore")

# ---------- token è®¡æ•° ----------
try:
    import tiktoken
    enc = tiktoken.get_encoding("cl100k_base")
    def count_tokens(text: str) -> int:
        return len(enc.encode(text))
except ModuleNotFoundError:
    def count_tokens(text: str) -> int:
        return len(text.split())

# ---------- wordfreq (optional) ----------
try:
    from wordfreq import zipf_frequency
    WORD_FREQ_READY = True
    def is_common_word(w: str) -> bool:
        return zipf_frequency(w.lower(), "en") > 1.5
except ModuleNotFoundError:
    WORD_FREQ_READY = False
    def is_common_word(w: str) -> bool:
        return True

# ---------- è·¯å¾„ ----------
INPUT_DIR  = r"C:\\Users\\24179\\Desktop\\whisper-transcription-project\\data_audio"
OUT_TRAIN  = r"C:\\Users\\24179\\Desktop\\whisper-transcription-project\\data_result\\training_data.json"
OUT_MARKUP = r"C:\\Users\\24179\\Desktop\\whisper-transcription-project\\data_result\\markup.json"
os.makedirs(os.path.dirname(OUT_TRAIN), exist_ok=True)

# ---------- å…¶ä»–å‚æ•° ----------
SUPPORTED    = (".mp3", ".wav", ".m4a", ".flac", ".aac", ".ogg", ".wma", ".webm")
FFMPEG_OPTS  = ["-ar", "16000", "-ac", "1"]
WHISPER_MOD  = "base"   # tiny / base / small / medium / large
WHISPER_DEV  = "cpu"    # æ”¹ "cuda" å¦‚æœ‰æ˜¾å¡
CONF_THR     = 0.7      # ç½®ä¿¡åº¦é˜ˆå€¼
PAUSE_THR    = 0.4      # ç§’ï¼Œè§†ä¸ºåœé¡¿
BAR_LEN      = 28
FILLERS      = {"um", "uh", "like", "really", "actually"}

# ---------- å·¥å…· ----------

def ensure_ffmpeg():
    if subprocess.run(["ffmpeg", "-version"], capture_output=True).returncode:
        sys.exit("âŒ æœªæ£€æµ‹åˆ° ffmpegï¼Œè¯·å®‰è£…å¹¶é…ç½® PATH")


def to_wav(path: str) -> str:
    """ä¿è¯éŸ³é¢‘ä¸º 16â€‘kHz / å•å£°é“ WAVã€‚è‹¥ä¸æ˜¯åˆ™è½¬ç åˆ°ä¸´æ—¶æ–‡ä»¶ã€‚"""
    if path.lower().endswith(".wav"):
        meta=subprocess.run(["ffprobe","-v","error","-select_streams","a:0","-show_entries","stream=sample_rate,channels","-of","default=noprint_wrappers=1:nokey=1",path],text=True,capture_output=True).stdout.strip().splitlines()
        if meta and meta[0]=="16000" and meta[1]=="1":
            return path
    fd,tmp=tempfile.mkstemp(suffix=".wav");os.close(fd)
    if subprocess.run(["ffmpeg","-y","-i",path,*FFMPEG_OPTS,tmp],capture_output=True).returncode:
        os.remove(tmp);raise RuntimeError("ffmpeg è½¬ç å¤±è´¥:"+path)
    return tmp


def whisper_transcribe(model, wav):
    with open(os.devnull, "w") as devnull, redirect_stdout(devnull), redirect_stderr(devnull):
        return model.transcribe(wav, verbose=False, word_timestamps=True)

# ---------- åœé¡¿ / æ ‡æ³¨ ----------

def split_words(segs):
    return [w for seg in segs for w in seg.get("words", [])]


def detect_pauses(words, thr=PAUSE_THR):
    pauses, prev_end = [], None
    for w in words:
        if prev_end is not None:
            gap = w["start"] - prev_end
            if gap >= thr:
                pauses.append(round(gap, 2))  # ä»…è®°å½•æ—¶é•¿
        prev_end = w["end"]
    return pauses


def build_markup(words, pauses):
    """ç”Ÿæˆçº¯æ–‡æœ¬ & å« HTML æ ‡æ³¨å­—ç¬¦ä¸²ã€‚åœé¡¿åœ¨ markup ä¸­æ’ â¸ã€‚"""
    plain, html_parts, errs = [], [], []
    pauses_iter = iter(pauses)
    next_pause_idx, next_pause = 0, next(pauses_iter, None)

    for w in words:
        # æ’å…¥è¯¥è¯å‰çš„åœé¡¿æ ‡è®°
        if next_pause is not None and w["start"]-0.001 > 0 and next_pause_idx < len(pauses):
            html_parts.append(f'<span class="pause" data-dur="{next_pause}">â¸ {next_pause}s</span>')
            next_pause_idx += 1
            next_pause = next(pauses_iter, None)

        tok = w["word"]
        plain.append(tok)
        low = w.get("confidence", 1) < CONF_THR
        uncommon = not is_common_word(tok) if WORD_FREQ_READY else False
        cls = None
        if tok.lower() in FILLERS:
            cls = "filler"
        elif (low or uncommon) and not tok.istitle():
            cls = "err"; errs.append({"w": tok.strip(), "conf": round(w.get("confidence",1),3)})
        html_parts.append(f'<span class="{cls}">{html.escape(tok)}</span>' if cls else html.escape(tok))

    return " ".join(plain).strip(), "".join(html_parts).strip(), errs


def make_compact(text, max_chars=400):
    return " ".join(t for t in re.sub(r"\s+", " ", text).split() if t.lower() not in FILLERS)[:max_chars]

# ---------- ä¸»å…¥å£ ----------

def main():
    ensure_ffmpeg()
    print(f"Whisper Splitter â€¢ {datetime.now():%F %T}")
    model = whisper.load_model(WHISPER_MOD, device=WHISPER_DEV)

    audios = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith(SUPPORTED)]
    if not audios:
        print("âš ï¸ è¾“å…¥ç›®å½•ä¸ºç©º"); return

    train, markup, tot_tokens = {}, {}, 0

    for idx, file in enumerate(audios, 1):
        bar = "â–ˆ"*int(BAR_LEN*idx/len(audios)) + "â–‘"*(BAR_LEN-int(BAR_LEN*idx/len(audios)))
        print(f"\r[{bar}] {idx}/{len(audios)} {file}", end="", flush=True)

        wav = to_wav(os.path.join(INPUT_DIR, file))
        res = whisper_transcribe(model, wav)
        words = split_words(res["segments"])
        pauses = detect_pauses(words)
        plain, html_out, errs = build_markup(words, pauses)

        tok = count_tokens(plain); tot_tokens += tok
        key = f"{os.path.splitext(file)[0]}_T{tok}{os.path.splitext(file)[1]}"

        train[key] = {
            "plain": plain,
            "compact": make_compact(plain),
            "tokens": tok,
            "errors": errs,
            "pause_count": len(pauses),
            "pause_total": round(sum(pauses), 2)
        }
        markup[key] = html_out

    print("\nâœ… å®Œæˆï¼Œæ€» token:", tot_tokens)
    with open(OUT_TRAIN, "w", encoding="utf-8") as fp: json.dump(train, fp, ensure_ascii=False, indent=2)
    with open(OUT_MARKUP, "w", encoding="utf-8") as fp: json.dump(markup, fp, ensure_ascii=False, indent=2)
    print("ğŸ“„ ä¿å­˜:", OUT_TRAIN, "|", OUT_MARKUP)

if __name__ == "__main__":
    main()
